q()
plot(1,20)
plot(10, 23)
library(RODBC)
m = odbcConnect(db,uid="16393",pwd="123456")
m = odbcConnect("db",uid="16393",pwd="123456")
# m = odbcConnect("db",uid="16393",pwd="123456")
m = odbcConnect("tabler",uid="16394",pwd="123456")
library(RODBC)
m = odbcConnect("db",uid="16393",pwd="123456")
setwd("C://Users/pc/Documents/Магистратура/R")
setwd("C://Users/pc/Documents/Магистратура/R")
#очищаем рабочее пространство
rm (list=ls())
#очищаем рабочее пространство
rm (list=ls())
# Прочитаем файл с данными в переменную flagdata
flagdata <- read.csv("flagData.txt", head = FALSE, sep=",") #, sep="\t"
setwd("C://Users/pc/Documents/Магистратура/2 семестр/R/task3 kNN")
getwd()
#очищаем рабочее пространство
rm (list=ls())
# Прочитаем файл с данными в переменную flagdata
flagdata <- read.csv("flagData.txt", head = FALSE, sep=",") #, sep="\t"
flagdata
#очищаем рабочее пространство
rm (list=ls())
setwd("C://Users/pc/Documents/Магистратура/2 семестр/R/task4 NBK")
setwd("C://Users/pc/Documents/Магистратура/2 семестр/R/task4 НБК")
getwd()
#очищаем рабочее пространство
rm (list=ls())
setwd("C://Users/pc/Documents/Магистратура/2 семестр/R/task4 НБК")
getwd()
#очищаем рабочее пространство
rm (list=ls())
# Прочитаем файл с данными в переменную flagdata
flagdata <- read.csv("flagData.txt", head = FALSE, sep=",") #, sep="\t"
# Формула нормализации данных
normalize <- function(x) {return ((x - min(x)) / (max(x) - min(x)))}
# Нормализуем данные
# исключим не численные факторы и переменную отклика
flag <- as.data.frame(lapply(flagdata[c(2:6, 8:17, 19:28)], normalize))
m = dim(wine)[2] # количество факторов # 26
m = dim(flag)[2] # количество факторов # 26
m
m = dim(flagdata)[2] # количество факторов # 26
m
install.packages("e1071")
# Подключим пакет e1071
library("e1071")
setwd("C://Users/pc/Documents/Магистратура/2 семестр/R/task4 НБК")
getwd()
#очищаем рабочее пространство
rm (list=ls())
# Прочитаем файл с данными в переменную flagdata
flagdata <- read.csv("flagData.txt", head = FALSE, sep=",") #, sep="\t"
# str(flagdata) # структура данных
flagdata
# Формула нормализации данных
normalize <- function(x) {return ((x - min(x)) / (max(x) - min(x)))}
# Нормализуем данные
# исключим не численные факторы и переменную отклика
flag <- as.data.frame(lapply(flagdata[c(2:6, 8:17, 19:28)], normalize))
dims = dim(flag) # n * m
n = dims[1] # объём выборки # 194
m = dims[2] # количество факторов # 25
# добавим перменную отклика в конец для удобства
flag[m+1] = flagdata[7]
flag
# Сохраним объём всей выборки и объём обучающей выборки в переменных
n_data = n
n_train = 110
# Подсчитаем частоты встречаемости классов в исходной выборке
# (выразим эти частоты в %, округлив результат до десятых)
round(prop.table(table(flag[m+1]))*100, digits = 1) # априорные вероятности гипотез (классов) (p(Hk))
# Чтобы обеспечить репрезентативность выборки, перемешаем её
set.seed(12345)
flagdata_mixed=flag[order(runif(n_data)),]
# Выберем обучающую выборку
train_data = flagdata_mixed[1:n_train,]
# Сохраним номера классов для строк обучающей выборки
train_data_labels = train_data[,m+1]
# формирование меток соответствующих уровней значения переменной отклика
train_data_labels<-factor(train_data_labels)
# Подсчитаем частоту присутствия каждого класса в обучающей выборке
# и сравним с соответствующими частотами в исходной выборке
round(prop.table(table(train_data[m+1]))*100, digits = 1)
# Оставшуюся часть "перемешанной выборки" будем использовать как тестовую выборку
test_data = flagdata_mixed[(n_train+1):n_data, ]
test_data_labels = test_data[,m+1]
# Удалим из обучающей и тестовой выборок столбец с номерами классов
train_data = train_data[-(m+1)]
test_data = test_data[-(m+1)]
# Подключим пакет e1071
library("e1071")
# Вызовем наивный Байесовский классификатор:
my_classifier <- naiveBayes(train_data,
train_data_labels)
# Для оценки качества прогноза
# подключим библиотеку gmodels
library("gmodels")
# Построим кросс-валидационную таблицу:
CrossTable(x = test_data_labels, y = data_test_pred, prop.chisq=TRUE)
# Передаём обучающую выборку: факторы (train_data)
# и метки классов (train_data_labels)
# Определим ("спрогнозируем") метки для тестовых данных
data_test_pred <- predict(my_classifier, test_data)
# Построим кросс-валидационную таблицу:
CrossTable(x = test_data_labels, y = data_test_pred, prop.chisq=TRUE)
setwd("C://Users/pc/Documents/Магистратура/2 семестр/R/task3 kNN")
getwd()
#очищаем рабочее пространство
rm (list=ls())
# Прочитаем файл с данными в переменную flagdata
flagdata <- read.csv("flagData.txt", head = FALSE, sep=",") #, sep="\t"
flagdata
# Формула нормализации данных
normalize <- function(x) {return ((x - min(x)) / (max(x) - min(x)))}
# Нормализуем данные
# исключим не численные факторы и переменную отклика
flag <- as.data.frame(lapply(flagdata[c(2:6, 8:17, 19:28)], normalize))
# добавим перменную отклика в конец для удобства
flag[26] = flagdata[7]
flag
# Сохраним объём всей выборки и объём обучающей выборки в переменных
n_data = 194
n_train = 110
# Подсчитаем частоты встречаемости классов в исходной выборке
# (выразим эти частоты в %, округлив результат до десятых)
round(prop.table(table(flag[26]))*100, digits = 1)
# Чтобы обеспечить репрезентативность выборки, перемешаем её
set.seed(12345)
flagdata_mixed=flag[order(runif(n_data)),]
# Выберем обучающую выборку
train_data = flagdata_mixed[1:n_train,]
# Сохраним номера классов для строк обучающей выборки
train_data_labels = train_data[,26]
# Подсчитаем частоту присутствия каждого класса в обучающей выборке
# и сравним с соответствующими частотами в исходной выборке
round(prop.table(table(train_data[26]))*100, digits = 1)
# Оставшуюся часть "перемешанной выборки" будем использовать
# как тестовую выборку
test_data = flagdata_mixed[(n_train+1):n_data, ]
test_data_labels = test_data[,26]
# Удалим из обучающей и тестовой выборок столбец с номерами классов
train_data = train_data[-26]
test_data = test_data[-26]
# Подключим пакет class
library("class")
data_test_pred <- knn(train = train_data,
test = test_data,
cl = train_data_labels,
k = round(sqrt(n_train)))
# Вызовем метод knn для тестовых данных
# Результат (номера классов) запишем в вектор data_test_pred
# Для оценки качества прогноза
# подключим библиотеку gmodels
library("gmodels")
# Построим кросс-валидационную таблицу:
CrossTable(x = test_data_labels, y = data_test_pred, prop.chisq=FALSE)
# Зададим новые данные
predict <- read.csv("predict.txt", sep=",", head=FALSE)
train_data
test_data_labels = test_data[,26]
test_data_labels
round(prop.table(table(test_data_labels))*100, digits = 1)
round(prop.table(table(train_data_labels))*100, digits = 1)
train_data_labels
setwd("C://Users/pc/Documents/Магистратура/2 семестр/R/task4 НБК")
getwd()
#очищаем рабочее пространство
rm (list=ls())
# Прочитаем файл с данными в переменную flagdata
flagdata <- read.csv("flagData.txt", head = FALSE, sep=",") #, sep="\t"
# str(flagdata) # структура данных
flagdata
# Формула нормализации данных
normalize <- function(x) {return ((x - min(x)) / (max(x) - min(x)))}
# Нормализуем данные
# исключим не численные факторы и переменную отклика
flag <- as.data.frame(lapply(flagdata[c(2:6, 8:17, 19:28)], normalize))
dims = dim(flag) # n * m
n = dims[1] # объём выборки # 194
m = dims[2] # количество факторов # 25
# добавим перменную отклика в конец для удобства
flag[m+1] = flagdata[7]
flag
# Сохраним объём всей выборки и объём обучающей выборки в переменных
n_data = n
n_train = 110
# Подсчитаем частоты встречаемости классов в исходной выборке
# (выразим эти частоты в %, округлив результат до десятых)
round(prop.table(table(flag[m+1]))*100, digits = 1) # априорные вероятности гипотез (классов) (p(Hk))
# Чтобы обеспечить репрезентативность выборки, перемешаем её
set.seed(12345)
flagdata_mixed=flag[order(runif(n_data)),]
# Выберем обучающую выборку
train_data = flagdata_mixed[1:n_train,]
# Сохраним номера классов для строк обучающей выборки
train_data_labels = train_data[,m+1]
# формирование меток соответствующих уровней значения переменной отклика
train_data_labels<-factor(train_data_labels)
# Подсчитаем частоту присутствия каждого класса в обучающей выборке
# и сравним с соответствующими частотами в исходной выборке
round(prop.table(table(train_data[m+1]))*100, digits = 1)
# Оставшуюся часть "перемешанной выборки" будем использовать как тестовую выборку
test_data = flagdata_mixed[(n_train+1):n_data, ]
test_data_labels = test_data[,m+1]
# Удалим из обучающей и тестовой выборок столбец с номерами классов
train_data = train_data[-(m+1)]
test_data = test_data[-(m+1)]
# Подключим пакет e1071
library("e1071")
# Вызовем наивный Байесовский классификатор:
my_classifier <- naiveBayes(train_data,
train_data_labels)
# Передаём обучающую выборку: факторы (train_data)
# и метки классов (train_data_labels)
# Определим ("спрогнозируем") метки для тестовых данных
data_test_pred <- predict(my_classifier, test_data)
# Для оценки качества прогноза
# подключим библиотеку gmodels
library("gmodels")
# Построим кросс-валидационную таблицу:
CrossTable(x = test_data_labels, y = data_test_pred, prop.chisq=TRUE)
# Зададим новые данные
predict <- read.csv("predict.txt", sep=",", head=FALSE)
predict = predict[c(2:6, 8:17, 19:28)]
# Определим значение переменной отклика (номер класса) для новых данных
new_predict <- predict(my_classifier, predict)
new_predict
# Зададим новые данные
predict <- read.csv("predict.txt", sep=",", head=FALSE)
predict[7]
